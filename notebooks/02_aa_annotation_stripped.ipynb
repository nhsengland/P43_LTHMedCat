{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotating documents using publicly-available SNOMED models on LTH data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     \n",
    "    author: naa\n",
    "    created: 2023-04-03\n",
    "    version: 0.1.0\n",
    "\n",
    "This is the annotation folder for the Public SNOMED model trained on LTH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = \"/home/jovyan/nhsx_nlp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models and prepare MedCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = dir_root + \"/models/mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5/vocab.dat\"\n",
    "cdb_path = dir_root + \"/models/mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5/cdb.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model path to Public model\n",
    "MEDCAT_MODEL_PATH = Path(\n",
    "    dir_root + \"/models/mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5\"\n",
    ")\n",
    "logging.debug(f\"Loading MedCAT models from {MEDCAT_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise cdb\n",
    "cdb = CDB()\n",
    "\n",
    "#load cdb\n",
    "cdb = CDB.load(dir_root + \"/models/mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5/cdb.dat\")\n",
    "\n",
    "# Create and load the Vocabulary\n",
    "vocab = Vocab()\n",
    "vocab = Vocab.load(vocab_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdb, len_cdb = common_setupConfig(cdb,MEDCAT_MODEL_PATH)\n",
    "len_cdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise meta annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_paths = [i for i in MEDCAT_MODEL_PATH.glob(\"meta_*\") if i.is_dir()]\n",
    "meta_cats = [MetaCAT.load(save_dir_path=meta_path) for meta_path in meta_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise CAT (main class from medcat used for concept annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat,ts = common_initialiseCAT(cdb, vocab, meta_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add semantic tag field to SNOMED-CT CDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add SNOMED-CT semantic tag to understand type_ids\n",
    "typeid2name = cat.cdb.addl_info['type_id2name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dir_root + \"/data/raw/neurology_letters_2023_03_18.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check CAT class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test NER+L on one single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text  = \"He was diagnosed with a neurology issue\"\n",
    "doc = cat(text)\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check type of document\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.get_entities(\"He was diagnosed with a neurology issue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all sentences selected for NER+L\n",
    "data= df[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test multiprocessing annotator function on one document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]['doctext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process one document into correct format for multiprocessing (list of two-element tuples )\n",
    "in_data =[(1,\"He was a neurology patient\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiprocess and check results \n",
    "results = cat.multiprocessing(in_data,nproc=2) # first argument is input data, second argument is number of processors\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check named entities with displacy\n",
    "displacy.render(cat(in_data[0]), style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data iterator for multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  data has to be in the form of a list of tuples containing two elements each: docid and doctext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unhash the following and filter data of selected length\n",
    "\n",
    "#data = data[data.doctext.apply(lambda x: len(str(x))>10)] #select data with length of >10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check filtered data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data iterator in [(docid, text), (docid, text)...] format\n",
    "in_data=[]\n",
    "for docid, row in data[['doctext']].iterrows():\n",
    "    #print(docid)\n",
    "    text=row['doctext']\n",
    "    in_data.append((docid,text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocess based on number of documents (alternative way to multiprocessing based on number of characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function does not always work\n",
    "# Set the batch size to the number of documents\n",
    "batch_size = 100 # Batch size (BS) in number of documents\n",
    "\n",
    "# Run model\n",
    "if __name__ == '__main__':\n",
    "    import torch\n",
    "    torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "    results_pipe = cat.multiprocessing_pipe(in_data[:1000], # Formatted data\n",
    "                                       batch_size = batch_size,\n",
    "                                       nproc=2) # Increase it when having more cores available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocess based on number of characters in documents, select 8 processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_chars = 500000\n",
    "\n",
    "results = cat.multiprocessing(in_data, batch_size_chars=batch_size_chars, nproc=8) # try with small document number first if preferred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check result of multiprocessing with baseline model on one document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of input data correspondes to the key of the annotated results, allowing for inspection of input text and extracted entitites\n",
    "data.iloc[550]['doctext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[550]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned list of `entities` contains the following:\n",
    "\n",
    "`acc` - Confidence score for this detection\n",
    "\n",
    "`cui` - ID of the detected entity in the CDB (in our case UMLS)\n",
    "\n",
    "`pretty_name` - The pretty name for this entity linked with the CUI\n",
    "\n",
    "`detected_name` - What exact source value was detected\n",
    "\n",
    "`type_ids` - The category code\n",
    "\n",
    "`types` - Description label of the type_ids\n",
    "\n",
    "`start` - The start character for the entity in the original string\n",
    "\n",
    "`end` - End character for the entity in the original string\n",
    "\n",
    "`id` - Internal ID, each entity inside a document has an unique ID\n",
    "\n",
    "`meta_anns ` - Each key is a customised meta-annotation task. \n",
    "\n",
    "\n",
    "__Optional parameters which can also be set:__\n",
    "\n",
    "The following can also be set to be returned during the creation of the MedCAT CDB within the model pack\n",
    "\n",
    "`icd10` - If we are using a medical CDB, we'll also get ICD10 codes\n",
    "\n",
    "`umls` - If the CDB was something other than UMLS, we would get the potential link to UMLS.\n",
    "\n",
    "`snomed` - If we are using a medical CDB this would link to the equivalent SNOMED concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check entities extracted for one document in structured annotation corpus\n",
    "for annotation in list(results[550]['entities'].values()):\n",
    "    print(annotation)\n",
    "    #print(list(results[3]['entities'].values()))\n",
    "    #print(annotation['cui'],annotation['pretty_name'])\n",
    "    print(annotation['meta_anns']['Status']['value'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save structured corpus of data annotated from baseline model: mc_modelpack_snomed_int_16_mar_2022_25be3857ba34bdd5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = dir_root + '/data/interim/Annotated_Public/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results, open(DATA_DIR+'2023_05_15_public_annotated_results.dat','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten nested dictionary of annotated results for easy inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load untrained structured annotation corpus if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open(DATA_DIR + '2023_05_15_public_annotated_results.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check length of multiprocessed corpus is the same as original corpus\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise empty dictionary for relevant keys to be extracted from multiprocessed results\n",
    "flat_data = {\n",
    "    'docid': [], # most superficial key in annotated results\n",
    "    'cui': [], #concept unique identifier\n",
    "    'pretty_name': [], #name of concept entity is linked to\n",
    "    'source_value': [], # detected entity\n",
    "    'detected_name': [], # detected entity\n",
    "    'type': [], # semantic type (may not be one-to-one, whereby concepts can be mapped to more than one type)\n",
    "    'context_similarity': [],\n",
    "    'text': [], #pulled from doctext in raw data    \n",
    "    'meta_status': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flattened dictionary of results for each entity and their locations, CUI, pretty_name, source value, type(s), context similarity, text and meta-annotation \n",
    "for doc in list(results.keys()):\n",
    "\n",
    "    for entity in list(results[doc]['entities'].values()):\n",
    "        \n",
    "        flat_data['docid'].append(doc)\n",
    "        flat_data['cui'].append(entity['cui'])\n",
    "        flat_data['pretty_name'].append(entity['pretty_name'])\n",
    "        flat_data['source_value'].append(entity['source_value'])\n",
    "        flat_data['detected_name'].append(entity['detected_name'])\n",
    "        flat_data['type'].append(entity['types'])#[0]) #comment this out as we're checking whether this is a one-one or one-many mapping for CUIs to TUIs\n",
    "        flat_data['context_similarity'].append(entity['context_similarity'])\n",
    "        flat_data['text'].append(data.iloc[doc]['doctext'])\n",
    "        flat_data['meta_status'].append(entity['meta_anns']['Status']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if CUIs map to more than 1 semantic type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of lengths of semantic type for each concept\n",
    "listtype = []\n",
    "for typelist in df_flat.type:\n",
    "    if not typelist == 'Nil':\n",
    "        listtype.append(len(typelist))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make set of listtype. If there is only the number on in the set, then all concepts map one-to-one to each type\n",
    "set_type = set(listtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> CUIs have a one-one relationship with semantic types. \n",
    "# Therefore we can confidently re-use the code in the following cell, \n",
    "# and access the 0'th element in \"entity['types']\"\" list, confidently knowing that we only have one element in that list\n",
    "set_type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reinitialise empty dictionary for flat data\n",
    "flat_data = {\n",
    "    'docid': [], # most superficial key in annotated results\n",
    "    'cui': [],\n",
    "    'pretty_name': [],\n",
    "    'source_value': [],\n",
    "    'detected_name': [],\n",
    "    'type': [],\n",
    "    'context_similarity': [],\n",
    "    'text': [], #pulled from doctext in raw data    \n",
    "    'meta_status': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flattened dictionary of results for each entity and their locations, CUI, pretty_name, source value, type, context similarity, text and meta-annotation \n",
    "for doc in list(results.keys()):\n",
    "\n",
    "    for entity in list(results[doc]['entities'].values()):\n",
    "        \n",
    "        flat_data['docid'].append(doc)\n",
    "        flat_data['cui'].append(entity['cui'])\n",
    "        flat_data['pretty_name'].append(entity['pretty_name'])\n",
    "        flat_data['source_value'].append(entity['source_value'])\n",
    "        flat_data['detected_name'].append(entity['detected_name'])\n",
    "        flat_data['type'].append(entity['types'][0]) #comment this out as we're checking whether this is a one-one or one-many mapping for CUIs to TUIs\n",
    "        flat_data['context_similarity'].append(entity['context_similarity'])\n",
    "        flat_data['text'].append(data.iloc[doc]['doctext'])\n",
    "        flat_data['meta_status'].append(entity['meta_anns']['Status']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check value length of each key in dictionary and confirm they are the same before converting them to dataframe\n",
    "for i in flat_data.keys():\n",
    "    print(len(flat_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat = pd.DataFrame.from_dict(flat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save flattened annotated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path(dir_root + '/data/interim/Annotated_Public/2023_05_15_public_annotated_flattened_results.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_flat.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect flattened annotation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data saved above for inspection if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat = pd.read_csv(dir_root + '/data/interim/Annotated_Public/2023_05_15_public_annotated_flattened_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect data\n",
    "df_flat.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dict of CUIs and their location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be a map from CUI to a list of documents where it appears: {\"cui\": [<doc_id>, <doc_id>, ...], ..}\n",
    "cui_location = {}\n",
    "for doc in list(results.keys()):\n",
    "    for annotation in list(results[doc]['entities'].values()):\n",
    "        if annotation['cui'] in cui_location:\n",
    "            cui_location[annotation['cui']].append(doc)\n",
    "        else:\n",
    "            cui_location[annotation['cui']] = [doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check length of dictionary. This should be the same as unique values of CUIs in flattened dataframe above\n",
    "len(cui_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dict of type ids and their location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the type_ids and their corresponding documents\n",
    "# Remember that a cui may map to more than one type_ids (one to many mapping), but we have checked this before flattening annotation results\n",
    "# Let's also save the type_ids location\n",
    "type_ids_location = {}\n",
    "for cui in cui_location.keys():\n",
    "   #print(cui, list(cat.cdb.cui2type_ids[cui]))\n",
    "    #print(cui_location[cui])\n",
    "   type_ids_location[list(cat.cdb.cui2type_ids[cui])[0]] = cui_location[cui]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(type_ids_location) # this should correspond to unique values of type in flattened annotation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dict of CUIS and their context similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be a map from CUI its context similarities : {\"cui\": [<context similarity>, <context similarity>, ...], ..}\n",
    "cui_similarity = {}\n",
    "\n",
    "for doc in list(results.keys()):\n",
    "    for annotation in list(results[doc]['entities'].values()):\n",
    "        if annotation['cui'] in cui_similarity:\n",
    "         cui_similarity[annotation['cui']].append(annotation['context_similarity'])\n",
    "        else:\n",
    "         cui_similarity[annotation['cui']] = [annotation['context_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cui_similarity) #this should be the same as unique numbers of CUIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save untrained CUI location, type ID location and CUI_context similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data so that we don't have to do the annotation again\n",
    "pickle.dump(cui_location, open(DATA_DIR + \"cui_location.dat\", 'wb'))\n",
    "pickle.dump(type_ids_location, open(DATA_DIR + \"type_ids_location.dat\", 'wb'))\n",
    "pickle.dump(cui_similarity, open(DATA_DIR + \"cui_similarity.dat\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load untrained annotated results from  public SNOMED model on Data, CUI location, type id location, context similarity and meta task of status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_results = pickle.load(open(DATA_DIR + '2023_05_15_public_annotated_results.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check loaded data\n",
    "untrained_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_location = pickle.load(open(DATA_DIR + 'cui_location.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ids_location = pickle.load(open(DATA_DIR + 'type_ids_location.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_similarity = pickle.load(open(DATA_DIR + 'cui_similarity.dat','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise annotation frequency for untrained public model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create df (df_cui_ndocs) of CUI, locations, type ids, cui similarity for ease of visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_ndocs = [('cui', 'ndocs')]\n",
    "\n",
    "for cui in cui_location.keys():\n",
    "    cui_ndocs.append((cui, len(cui_location[cui])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cui_ndocs = pd.DataFrame(cui_ndocs[1:], columns=cui_ndocs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add type ids for each CUI\n",
    "\n",
    "df_cui_ndocs['type_ids'] = ['unk'] * len(df_cui_ndocs)\n",
    "cols = list(df_cui_ndocs.columns)\n",
    "\n",
    "for i in range(len(df_cui_ndocs)):\n",
    "    cui = df_cui_ndocs.iat[i, cols.index('cui')]\n",
    "    type_ids = cat.cdb.cui2type_ids.get(cui, 'unk')\n",
    "    df_cui_ndocs.iat[i, cols.index('type_ids')] = type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add type id semantic tag for each CUI\n",
    "semantic_tag =[]\n",
    "for i, row in df_cui_ndocs.iterrows():\n",
    "    key = tuple(row['type_ids'])[0]\n",
    "    #print(i, key, type(key))\n",
    "    #print(key, typeid2name[key])\n",
    "    semantic_tag.append(typeid2name[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cui_ndocs['Semantic_tags'] = semantic_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add name for each CUI\n",
    "df_cui_ndocs['name'] = ['unk'] * len(df_cui_ndocs)\n",
    "cols = list(df_cui_ndocs.columns)\n",
    "for i in range(len(df_cui_ndocs)):\n",
    "    cui = df_cui_ndocs.iat[i, cols.index('cui')]\n",
    "    name = cat.cdb.cui2preferred_name.get(cui, 'unk')\n",
    "    df_cui_ndocs.iat[i, cols.index('name')] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the percentage column\n",
    "total_docs = len(data)\n",
    "df_cui_ndocs['perc_docs'] = (df_cui_ndocs['ndocs'] / total_docs) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mean of context similarity per cui \n",
    "cons_similarity = []\n",
    "for _, row in df_cui_ndocs.iterrows():\n",
    "    cui = row['cui']\n",
    "    #print(cui)\n",
    "    mean_similarity = statistics.mean(cui_similarity[cui])\n",
    "    cons_similarity.append(mean_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cui_ndocs['mean_similarity'] = cons_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort dataframe by ndocs (number of documents with mention of CUI)\n",
    "df_cui_ndocs = df_cui_ndocs.sort_values('ndocs', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect new dataframe created\n",
    "df_cui_ndocs.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframe of CUIs, number of docs mentioning them, related semantic tags, concept name, and mean context similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path(dir_root + '/data/interim/Annotated_Public/2023_05_15_cui_docs.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_cui_ndocs.to_csv(filepath, index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cui and docs data again if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cui_ndocs = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect df loaded\n",
    "df_cui_ndocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot count of unfiltered concepts extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 30 concepts\n",
    "sns.reset_defaults()\n",
    "sns.set(\n",
    "    rc={'figure.figsize':(10, 15)}, \n",
    "    style=\"whitegrid\",\n",
    "    palette='pastel'\n",
    ")\n",
    "f, ax = plt.subplots()\n",
    "_data = df_cui_ndocs.iloc[0:30]\n",
    "sns.barplot(x=\"ndocs\", y=\"name\", data=_data, label=\"Concept\", color=\"b\")\n",
    "_ = ax.set(xlim=(0, 6000), ylabel=\"SNOMED-CT concept\", xlabel=\"Count of documents with mention of concept following annotation \\n of clinic letters with public SNOMED model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  plot count of top 30 SNOMED-CT concepts for type 9090192: Disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 30 concepts\n",
    "sns.reset_defaults()\n",
    "sns.set(\n",
    "    rc={'figure.figsize':(6,15)}, \n",
    "    style=\"whitegrid\",\n",
    "    palette='pastel'\n",
    ")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "# Subset the data and chose only 9090192, top 30\n",
    "_data = df_cui_ndocs[df_cui_ndocs['type_ids'].apply(lambda x: '9090192' in x)].iloc[:31]\n",
    "\n",
    "sns.barplot(x=\"ndocs\", y=\"name\", data=_data, label=\"Concept\", color=\"b\")\n",
    "_ = ax.set(xlim=(0, 2000), ylabel=\"SNOMED-CT concept\", xlabel=\"Count of documents with mention of concept\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  plot percentage of top 30 SNOMED-CT concepts for type 9090192: Disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#barplot for percentage of documents with mention of concept\n",
    "sns.reset_defaults()\n",
    "sns.set(\n",
    "    rc={'figure.figsize':(6,15)}, \n",
    "    style=\"whitegrid\",\n",
    "    palette='pastel',\n",
    "    )\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "# Subset the data and chose only 9090192, top 30\n",
    "_data = df_cui_ndocs[df_cui_ndocs['type_ids'].apply(lambda x: '9090192' in x)].iloc[:31]\n",
    "\n",
    "sns.barplot(x=\"perc_docs\", y=\"name\", data=_data, label=\"Concept Name\", color=\"b\")\n",
    "_ = ax.set(xlim=(0, 1.5), ylabel=\"Concept Name\", xlabel=\"Percentage of documents with mention of concept \\n for Public model annotation \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect data\n",
    "_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:18) \n[GCC 10.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
